<script setup lang="ts">
import { ref, computed, onMounted, onUnmounted } from 'vue'
import { useRouter } from 'vue-router'
import { open } from '@tauri-apps/plugin-dialog'
import { invoke } from '@tauri-apps/api/core'
import { getCurrentWebviewWindow } from '@tauri-apps/api/webviewWindow'
import { getCurrentWindow } from '@tauri-apps/api/window'
import { listen } from '@tauri-apps/api/event'
import { ElMessage, ElMessageBox } from 'element-plus'
import { useSubtitleStore } from '@/stores/subtitle'
import { useAudioStore } from '@/stores/audio'
import { useConfigStore } from '@/stores/config'
import { useSmartDictionaryStore } from '@/stores/smartDictionary'
import type { SRTFile, AudioFile, SubtitleEntry } from '@/types/subtitle'

interface WhisperModelInfo {
  name: string
  size: string
  downloaded: boolean
  path?: string
  partial_size?: number
}

interface TranscriptionProgress {
  progress: number
  current_text: string
  status: string
}

interface SenseVoiceEnvStatus {
  uv_installed: boolean
  env_exists: boolean
  ready: boolean
}

const router = useRouter()
const subtitleStore = useSubtitleStore()
const audioStore = useAudioStore()
const configStore = useConfigStore()
const smartDictionary = useSmartDictionaryStore()

const isDragging = ref(false)
const isLoading = ref(false)
const loadingMessage = ref('')

const showTranscriptionDialog = ref(false)
const availableModels = ref<WhisperModelInfo[]>([])
const isTranscribing = ref(false)
const transcriptionProgress = ref(0)
const transcriptionMessage = ref('')
const isCancelled = ref(false)
const isTransitioningToEditor = ref(false)

// SenseVoice ç›¸å…³çŠ¶æ€
const sensevoiceEnvStatus = ref<SenseVoiceEnvStatus>({ uv_installed: false, env_exists: false, ready: false })
const isInstallingSensevoice = ref(false)

// å·²ä¸‹è½½çš„æ¨¡å‹
const downloadedModels = computed(() => availableModels.value.filter(m => m.downloaded))

// å½“å‰é€‰ä¸­çš„æ¨¡å‹æ˜¾ç¤ºåç§°
const currentModelName = computed(() => {
  if (configStore.transcriptionEngine === 'sensevoice') {
    return 'SenseVoice'
  }
  const model = availableModels.value.find(m => m.name === configStore.whisperModel)
  if (model?.downloaded) return model.name
  // å¦‚æœé»˜è®¤æ¨¡å‹æœªä¸‹è½½ï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ªå·²ä¸‹è½½çš„æ¨¡å‹æˆ– base
  const firstDownloaded = downloadedModels.value[0]
  return firstDownloaded?.name || 'base'
})

// æ˜¯å¦æ˜¾ç¤ºå¼•æ“åˆ‡æ¢ä¸‹æ‹‰
const showEngineDropdown = computed(() => {
  return downloadedModels.value.length > 0 || sensevoiceEnvStatus.value.ready
})

// æ˜¯å¦æ˜¾ç¤ºä¸‹è½½è¿›åº¦æ¡ï¼ˆä¸‹è½½æ¨¡å‹æ—¶ï¼‰
const isDownloading = computed(() => {
  return transcriptionMessage.value.includes('Downloading') || 
         (transcriptionMessage.value.includes('ä¸‹è½½') && !transcriptionMessage.value.includes('é¦–æ¬¡'))
})

// æ˜¯å¦æ­£åœ¨ä½¿ç”¨ SenseVoice è½¬å½•ï¼ˆç°åœ¨ä¹Ÿæ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
const isSensevoiceTranscribing = computed(() => {
  return configStore.transcriptionEngine === 'sensevoice' && isTranscribing.value && !isInstallingSensevoice.value
})

// æ˜¯å¦æ˜¾ç¤ºçœŸå®è¿›åº¦æ¡ï¼ˆä¸‹è½½æ¨¡å‹æˆ– SenseVoice è½¬å½•æ—¶ï¼‰
const showRealProgress = computed(() => {
  return isDownloading.value || isSensevoiceTranscribing.value
})

// æœ¬åœ°åŒ–æ¶ˆæ¯
const localizedMessage = computed(() => {
  const msg = transcriptionMessage.value
  if (!msg) return 'å‡†å¤‡ä¸­...'
  
  // è‹±æ–‡æ¶ˆæ¯æ˜ å°„åˆ°ä¸­æ–‡
  const messageMap: Record<string, string> = {
    'Loading audio file...': 'æ­£åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶...',
    'Loading Whisper model...': 'æ­£åœ¨åŠ è½½è¯­éŸ³æ¨¡å‹...',
    'Transcribing audio...': 'æ­£åœ¨è¯†åˆ«è¯­éŸ³å†…å®¹...',
    'Converting to subtitles...': 'æ­£åœ¨ç”Ÿæˆå­—å¹•...',
  }
  
  // æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸‹è½½è¿›åº¦
  if (msg.includes('Downloading')) {
    const match = msg.match(/Downloading (\w+) model\.\.\. ([\d.]+)%/)
    if (match) {
      return `æ­£åœ¨ä¸‹è½½ ${match[1]} æ¨¡å‹... ${match[2]}%`
    }
    return 'æ­£åœ¨ä¸‹è½½æ¨¡å‹...'
  }
  
  // æ£€æŸ¥å®Œæˆæ¶ˆæ¯
  if (msg.includes('completed') || msg.includes('Generated')) {
    const match = msg.match(/Generated (\d+) subtitles/)
    if (match) {
      return `è½¬å½•å®Œæˆï¼ç”Ÿæˆäº† ${match[1]} æ¡å­—å¹•`
    }
    return 'è½¬å½•å®Œæˆï¼'
  }
  
  return messageMap[msg] || msg
})



let unlistenFileDrop: (() => void) | null = null

let unlistenTranscriptionProgress: (() => void) | null = null
let unlistenModelDownloadProgress: (() => void) | null = null

onMounted(async () => {
  const appWindow = getCurrentWebviewWindow()
  const unlistenHover = await appWindow.onDragDropEvent((event) => {
    if (event.payload.type === 'over') isDragging.value = true
    else if (event.payload.type === 'leave') isDragging.value = false
    else if (event.payload.type === 'drop') { isDragging.value = false; handleFileDrop(event.payload.paths) }
  })
  unlistenFileDrop = unlistenHover

  // ç›‘å¬è½¬å½•è¿›åº¦
  unlistenTranscriptionProgress = await listen<TranscriptionProgress>('transcription-progress', (event) => {
    transcriptionProgress.value = event.payload.progress
    transcriptionMessage.value = event.payload.current_text
  })

  // ç›‘å¬æ¨¡å‹ä¸‹è½½è¿›åº¦ï¼ˆå•ç‹¬äº‹ä»¶ï¼Œé¿å…ä¸è½¬å½•è¿›åº¦å†²çªï¼‰
  unlistenModelDownloadProgress = await listen<TranscriptionProgress>('model-download-progress', (event) => {
    transcriptionProgress.value = event.payload.progress
    transcriptionMessage.value = event.payload.current_text
  })

  try { availableModels.value = await invoke<WhisperModelInfo[]>('get_whisper_models') } catch (e) { console.error(e) }
  // æ£€æŸ¥ SenseVoice ç¯å¢ƒ
  try { sensevoiceEnvStatus.value = await invoke<SenseVoiceEnvStatus>('check_sensevoice_env_status') } catch (e) { console.error(e) }
})

onUnmounted(() => {
  if (unlistenFileDrop) unlistenFileDrop()
  if (unlistenTranscriptionProgress) unlistenTranscriptionProgress()
  if (unlistenModelDownloadProgress) unlistenModelDownloadProgress()
})

const handleFileDrop = async (paths: string[]) => {
  if (!paths || paths.length === 0) return
  const srtFile = paths.find((p) => p.toLowerCase().endsWith('.srt'))
  const audioFile = paths.find((p) => /\.(mp3|wav|ogg|flac|m4a|aac)$/i.test(p.toLowerCase()))
  if (!srtFile && !audioFile) {
    await ElMessageBox.alert('è¯·æ‹–æ”¾æœ‰æ•ˆçš„ SRT å­—å¹•æ–‡ä»¶æˆ–éŸ³é¢‘æ–‡ä»¶', 'æ— æ•ˆæ–‡ä»¶', { confirmButtonText: 'ç¡®å®š', type: 'warning' })
    return
  }
  await processFiles({ srtPath: srtFile, audioPath: audioFile })
}

const openSRTFile = async () => {
  try {
    const selected = await open({ multiple: false, filters: [{ name: 'SRT å­—å¹•æ–‡ä»¶', extensions: ['srt'] }] })
    if (selected) await processFiles({ srtPath: selected as string })
  } catch (e) { await ElMessageBox.alert('æ— æ³•æ‰“å¼€æ–‡ä»¶é€‰æ‹©å™¨', 'é”™è¯¯', { confirmButtonText: 'ç¡®å®š', type: 'error' }) }
}

const processFiles = async ({ srtPath, audioPath }: { srtPath?: string; audioPath?: string }) => {
  isLoading.value = true
  let srtLoaded = false
  try {
    if (srtPath) {
      loadingMessage.value = 'æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶...'
      const srtFile = await invoke<SRTFile>('read_srt', { filePath: srtPath })
      await subtitleStore.loadSRTFile(srtFile)
      srtLoaded = true
      configStore.addRecentFile(srtPath)
      if ((window as any).__updateRecentFilesMenu) await (window as any).__updateRecentFilesMenu()
    }
    if (audioPath) {
      loadingMessage.value = 'æ­£åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶...'
      const fileName = audioPath.split('/').pop() || 'audio'
      const fileExtension = audioPath.split('.').pop()?.toLowerCase() || 'mp3'
      await audioStore.loadAudio({ name: fileName, path: audioPath, duration: 0, format: fileExtension })
    }
    if (srtLoaded) { router.push('/editor') }
  } catch (error) {
    await ElMessageBox.alert(`åŠ è½½å¤±è´¥ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`, 'é”™è¯¯', { confirmButtonText: 'ç¡®å®š', type: 'error' })
  } finally { if (!srtLoaded) { isLoading.value = false; loadingMessage.value = '' } }
}

const formatRelativeTime = (timestamp: number): string => {
  const diff = Date.now() - timestamp
  const minutes = Math.floor(diff / 60000), hours = Math.floor(diff / 3600000), days = Math.floor(diff / 86400000)
  if (minutes < 1) return 'åˆšåˆš'
  if (minutes < 60) return `${minutes} åˆ†é’Ÿå‰`
  if (hours < 24) return `${hours} å°æ—¶å‰`
  if (days < 7) return `${days} å¤©å‰`
  const date = new Date(timestamp)
  return `${date.getMonth() + 1}/${date.getDate()}`
}

const openRecentFile = async (filePath: string) => {
  isLoading.value = true
  loadingMessage.value = 'æ­£åœ¨åŠ è½½å­—å¹•æ–‡ä»¶...'
  try {
    const srtFile = await invoke<SRTFile>('read_srt', { filePath })
    await subtitleStore.loadSRTFile(srtFile)
    configStore.addRecentFile(filePath)
    if ((window as any).__updateRecentFilesMenu) await (window as any).__updateRecentFilesMenu()
    router.push('/editor')
  } catch (error) {
    isLoading.value = false; loadingMessage.value = ''
    await ElMessageBox.alert(`åŠ è½½æ–‡ä»¶å¤±è´¥ï¼š${error instanceof Error ? error.message : 'æ–‡ä»¶å¯èƒ½å·²è¢«ç§»åŠ¨æˆ–åˆ é™¤'}`, 'åŠ è½½å¤±è´¥', { confirmButtonText: 'ç¡®å®š', type: 'error' })
    // æ–‡ä»¶åŠ è½½å¤±è´¥åè‡ªåŠ¨ä»æœ€è¿‘åˆ—è¡¨ä¸­åˆ é™¤
    configStore.removeRecentFile(filePath)
    if ((window as any).__updateRecentFilesMenu) await (window as any).__updateRecentFilesMenu()
  }
}

const removeRecentFile = (filePath: string, event: MouseEvent) => {
  event.stopPropagation()
  configStore.removeRecentFile(filePath)
  if ((window as any).__updateRecentFilesMenu) (window as any).__updateRecentFilesMenu()
}

let lastClickTime = 0
const onTitlebarMousedown = async (e: MouseEvent) => {
  if (e.button === 0) {
    const now = Date.now()
    if (now - lastClickTime < 300) { await onTitlebarDoubleClick(); return }
    lastClickTime = now
    e.preventDefault()
    try { await getCurrentWindow().startDragging() } catch {}
  }
}

const onTitlebarDoubleClick = async () => {
  const window = getCurrentWindow()
  if (await window.isMaximized()) await window.unmaximize()
  else await window.maximize()
}

const startTranscription = async () => {
  try {
    // å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶
    const selected = await open({ multiple: false, filters: [{ name: 'éŸ³é¢‘æ–‡ä»¶', extensions: ['mp3', 'wav', 'ogg', 'flac', 'm4a', 'aac'] }] })
    if (!selected || typeof selected !== 'string') return

    // æ ¹æ®å¼•æ“ç±»å‹å¤„ç†
    if (configStore.transcriptionEngine === 'sensevoice') {
      await startSensevoiceTranscription(selected)
    } else {
      await startWhisperTranscription(selected)
    }
  } catch (error) {
    isTranscribing.value = false
    showTranscriptionDialog.value = false
    if (isCancelled.value) return
    const errorMsg = error instanceof Error ? error.message : String(error)
    if (errorMsg.includes('å–æ¶ˆ') || errorMsg.includes('cancel')) return
    await ElMessageBox.alert(`è½¬å½•å¤±è´¥ï¼š${errorMsg}`, 'è½¬å½•å¤±è´¥', { confirmButtonText: 'ç¡®å®š', type: 'error' })
  }
}

// Whisper è½¬å½•
const startWhisperTranscription = async (audioPath: string) => {
  const modelName = configStore.whisperModel
  const model = availableModels.value.find(m => m.name === modelName)
  
  // å¦‚æœæ¨¡å‹æœªä¸‹è½½ï¼Œè‡ªåŠ¨ä¸‹è½½
  if (!model || !model.downloaded) {
    const targetModel = model || availableModels.value.find(m => m.name === 'base')!
    const confirm = await ElMessageBox.confirm(
      `æ¨¡å‹ ${targetModel.name} (${targetModel.size}) å°šæœªä¸‹è½½ï¼Œæ˜¯å¦ç°åœ¨ä¸‹è½½ï¼Ÿ`,
      'éœ€è¦ä¸‹è½½æ¨¡å‹',
      { confirmButtonText: 'ä¸‹è½½', cancelButtonText: 'å–æ¶ˆ', type: 'info' }
    ).catch(() => false)
    if (!confirm) return
    
    isTranscribing.value = true
    transcriptionProgress.value = 0
    transcriptionMessage.value = 'æ­£åœ¨ä¸‹è½½æ¨¡å‹...'
    showTranscriptionDialog.value = true
    try {
      await invoke('download_whisper_model', { modelSize: targetModel.name })
      availableModels.value = await invoke<WhisperModelInfo[]>('get_whisper_models')
      configStore.whisperModel = targetModel.name
      configStore.saveWhisperSettings()
    } catch (error) {
      isTranscribing.value = false
      showTranscriptionDialog.value = false
      await ElMessageBox.alert(`ä¸‹è½½æ¨¡å‹å¤±è´¥ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`, 'ä¸‹è½½å¤±è´¥', { confirmButtonText: 'ç¡®å®š', type: 'error' })
      return
    }
  }

  isTranscribing.value = true
  isCancelled.value = false
  transcriptionProgress.value = 0
  transcriptionMessage.value = 'æ­£åœ¨è½¬å½•éŸ³é¢‘...'
  showTranscriptionDialog.value = true
  
  const entries = await invoke<SubtitleEntry[]>('transcribe_audio_to_subtitles', {
    audioPath,
    modelSize: configStore.whisperModel,
    language: configStore.whisperLanguage,
  })
  
  if (isCancelled.value) return
  await finishTranscription(audioPath, entries)
}

// SenseVoice è½¬å½•
const startSensevoiceTranscription = async (audioPath: string) => {
  // æ£€æŸ¥ç¯å¢ƒ
  sensevoiceEnvStatus.value = await invoke<SenseVoiceEnvStatus>('check_sensevoice_env_status')
  
  if (!sensevoiceEnvStatus.value.ready) {
    // éœ€è¦å®‰è£…ç¯å¢ƒ
    const confirm = await ElMessageBox.confirm(
      'SenseVoice ç¯å¢ƒå°šæœªå®‰è£…ï¼Œéœ€è¦ä¸‹è½½çº¦ 2-3GB çš„ä¾èµ–ã€‚æ˜¯å¦ç°åœ¨å®‰è£…ï¼Ÿ',
      'éœ€è¦å®‰è£…ç¯å¢ƒ',
      { confirmButtonText: 'å®‰è£…', cancelButtonText: 'å–æ¶ˆ', type: 'info' }
    ).catch(() => false)
    if (!confirm) return
    
    if (!sensevoiceEnvStatus.value.uv_installed) {
      await ElMessageBox.alert(
        'è¯·å…ˆå®‰è£… uv åŒ…ç®¡ç†å™¨ã€‚\n\nå®‰è£…å‘½ä»¤ï¼š\nmacOS/Linux: curl -LsSf https://astral.sh/uv/install.sh | sh\nWindows: powershell -c "irm https://astral.sh/uv/install.ps1 | iex"',
        'éœ€è¦å®‰è£… uv',
        { confirmButtonText: 'ç¡®å®š', type: 'warning' }
      )
      return
    }
    
    // å®‰è£…ç¯å¢ƒ
    isInstallingSensevoice.value = true
    isTranscribing.value = true
    transcriptionProgress.value = 0
    transcriptionMessage.value = 'æ­£åœ¨å®‰è£… SenseVoice ç¯å¢ƒ...'
    showTranscriptionDialog.value = true
    
    // ç›‘å¬å®‰è£…è¿›åº¦
    const unlistenInstall = await listen<TranscriptionProgress>('sensevoice-progress', (event) => {
      transcriptionProgress.value = event.payload.progress
      transcriptionMessage.value = event.payload.current_text
    })
    
    try {
      await invoke('install_sensevoice')
      sensevoiceEnvStatus.value = await invoke<SenseVoiceEnvStatus>('check_sensevoice_env_status')
    } catch (error) {
      isTranscribing.value = false
      isInstallingSensevoice.value = false
      showTranscriptionDialog.value = false
      unlistenInstall()
      await ElMessageBox.alert(`å®‰è£…å¤±è´¥ï¼š${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`, 'å®‰è£…å¤±è´¥', { confirmButtonText: 'ç¡®å®š', type: 'error' })
      return
    }
    unlistenInstall()
    isInstallingSensevoice.value = false
  }

  isTranscribing.value = true
  isCancelled.value = false
  transcriptionProgress.value = 0
  transcriptionMessage.value = 'æ­£åœ¨è½¬å½•éŸ³é¢‘...'
  showTranscriptionDialog.value = true
  
  const entries = await invoke<SubtitleEntry[]>('transcribe_with_sensevoice_model', {
    audioPath,
    language: configStore.whisperLanguage,
  })
  
  if (isCancelled.value) return
  await finishTranscription(audioPath, entries)
}

// å®Œæˆè½¬å½•ï¼Œè·³è½¬ç¼–è¾‘å™¨
const finishTranscription = async (audioPath: string, entries: SubtitleEntry[]) => {
  // ğŸ”¥ è½¬å½•å®Œæˆåï¼Œç«‹å³åº”ç”¨æ™ºèƒ½è¯å…¸
  if (smartDictionary.totalCount > 0) {
    let replacementCount = 0
    for (const entry of entries) {
      const { result, replacements } = smartDictionary.applyDictionary(entry.text)
      if (replacements.length > 0) {
        entry.text = result
        replacementCount += replacements.length
      }
    }
    if (replacementCount > 0) {
      console.log(`æ™ºèƒ½è¯å…¸æ›¿æ¢äº† ${replacementCount} å¤„`)
    }
  }

  const fileName = audioPath.split('/').pop() || 'transcription.srt'
  const srtFileName = fileName.replace(/\.[^.]+$/, '.srt')
  // ç”Ÿæˆä¸éŸ³é¢‘æ–‡ä»¶åŒç›®å½•çš„ srt æ–‡ä»¶è·¯å¾„
  let srtPath = audioPath.replace(/\.[^.]+$/, '.srt')

  // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
  const fileExists = await invoke<boolean>('check_file_exists', { filePath: srtPath })
  if (fileExists) {
    // æš‚æ—¶éšè—è½¬å½•å¯¹è¯æ¡†ä»¥æ˜¾ç¤ºç¡®è®¤æ¡†
    showTranscriptionDialog.value = false

    try {
      await ElMessageBox.confirm(
        `æ–‡ä»¶ "${srtFileName}" å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ`,
        'æ–‡ä»¶å·²å­˜åœ¨',
        {
          confirmButtonText: 'è¦†ç›–',
          cancelButtonText: 'å¦å­˜ä¸º',
          distinguishCancelAndClose: true,
          type: 'warning',
        }
      )
      // ç”¨æˆ·é€‰æ‹©è¦†ç›–ï¼Œç»§ç»­ä½¿ç”¨åŸè·¯å¾„
    } catch (action) {
      if (action === 'cancel') {
        // ç”¨æˆ·é€‰æ‹©å¦å­˜ä¸º
        const { save } = await import('@tauri-apps/plugin-dialog')
        const newPath = await save({
          filters: [{ name: 'SRT å­—å¹•æ–‡ä»¶', extensions: ['srt'] }],
          defaultPath: srtPath,
        })
        if (newPath) {
          srtPath = newPath
        } else {
          // ç”¨æˆ·å–æ¶ˆäº†å¦å­˜ä¸ºï¼Œä¸ä¿å­˜æ–‡ä»¶ä½†ç»§ç»­è¿›å…¥ç¼–è¾‘å™¨
          srtPath = ''
        }
      } else {
        // ç”¨æˆ·å…³é—­äº†å¯¹è¯æ¡†ï¼Œä¸ä¿å­˜æ–‡ä»¶ä½†ç»§ç»­è¿›å…¥ç¼–è¾‘å™¨
        srtPath = ''
      }
    }
  }

  await subtitleStore.loadSRTFile({
    name: srtFileName,
    path: srtPath,
    entries,
    encoding: 'UTF-8',
  })

  // è‡ªåŠ¨ä¿å­˜å­—å¹•æ–‡ä»¶ï¼ˆå¦‚æœæœ‰è·¯å¾„ï¼‰
  if (srtPath) {
    try {
      await subtitleStore.saveToFile()
    } catch (error) {
      console.error('è‡ªåŠ¨ä¿å­˜å­—å¹•æ–‡ä»¶å¤±è´¥:', error)
    }
  }

  const fileExtension = audioPath.split('.').pop()?.toLowerCase() || 'mp3'
  await audioStore.loadAudio({ name: fileName, path: audioPath, duration: 0, format: fileExtension })

  isTranscribing.value = false
  isTransitioningToEditor.value = true
  setTimeout(() => {
    showTranscriptionDialog.value = false
    router.push('/editor')
  }, 800)
}

const cancelTranscription = async () => {
  isCancelled.value = true
  try {
    if (configStore.transcriptionEngine === 'sensevoice') {
      await invoke('cancel_sensevoice_task')
    } else {
      await invoke('cancel_transcription_task')
    }
  } catch (e) {
    console.error('å–æ¶ˆè½¬å½•å¤±è´¥:', e)
  }
  showTranscriptionDialog.value = false
  isTranscribing.value = false
  isTransitioningToEditor.value = false
  isInstallingSensevoice.value = false
}

const onSelectModel = (command: string) => {
  if (command === 'sensevoice') {
    configStore.transcriptionEngine = 'sensevoice'
  } else {
    configStore.transcriptionEngine = 'whisper'
    configStore.whisperModel = command
  }
  configStore.saveWhisperSettings()
}
</script>

<template>
  <div class="welcome-page" :class="{ 'is-dragging': isDragging }">
    <div class="titlebar" @mousedown.left="onTitlebarMousedown" @dblclick="onTitlebarDoubleClick">
      <span class="titlebar-title">SRT å­—å¹•ç¼–è¾‘å™¨</span>
    </div>

    <div class="welcome-content">
      <div class="main-section">
        <!-- å“ç‰ŒåŒºåŸŸ -->
        <div class="brand-area">
          <div class="brand-icon">
            <i class="i-mdi-subtitles-outline"></i>
          </div>
          <div class="brand-text">
            <h1 class="brand-title">SRT å­—å¹•ç¼–è¾‘å™¨</h1>
            <p class="brand-desc">ä¸“ä¸šçš„å­—å¹•ç¼–è¾‘å·¥å…·ï¼Œæ”¯æŒéŸ³é¢‘åŒæ­¥å’Œæ‰¹é‡æ“ä½œ</p>
          </div>
        </div>

        <!-- å¼€å§‹ä½¿ç”¨ -->
        <div class="get-started">
          <p class="section-title">å¼€å§‹ä½¿ç”¨</p>
          <div class="action-buttons">
            <button class="primary-btn" :disabled="isLoading" @click="openSRTFile">
              <span v-if="!isLoading">æ‰“å¼€å­—å¹•æ–‡ä»¶</span>
              <span v-else>{{ loadingMessage }}</span>
            </button>
            <div class="transcription-btn-group">
              <button class="transcription-btn" :disabled="isLoading" @click="startTranscription">
                <i class="i-mdi-microphone"></i>
                <span>AI è¯­éŸ³è½¬å½•</span>
                <span class="model-badge">{{ currentModelName }}</span>
              </button>
              <el-dropdown trigger="click" @command="onSelectModel">
                <button class="transcription-dropdown" :disabled="isLoading">
                  <i class="i-mdi-chevron-down"></i>
                </button>
                <template #dropdown>
                  <el-dropdown-menu>
                    <!-- Whisper æ¨¡å‹ -->
                    <el-dropdown-item disabled class="dropdown-header">Whisper</el-dropdown-item>
                    <el-dropdown-item
                      v-for="model in downloadedModels"
                      :key="model.name"
                      :command="model.name"
                      :class="{ 'is-active': configStore.transcriptionEngine === 'whisper' && model.name === configStore.whisperModel }"
                    >
                      {{ model.name }}
                    </el-dropdown-item>
                    <el-dropdown-item v-if="downloadedModels.length === 0" disabled>
                      æš‚æ— å·²ä¸‹è½½æ¨¡å‹
                    </el-dropdown-item>
                    <!-- SenseVoice (ä»…åœ¨å·²å®‰è£…æ—¶æ˜¾ç¤º) -->
                    <template v-if="sensevoiceEnvStatus.ready">
                      <el-dropdown-item divided disabled class="dropdown-header">SenseVoice</el-dropdown-item>
                      <el-dropdown-item
                        command="sensevoice"
                        :class="{ 'is-active': configStore.transcriptionEngine === 'sensevoice' }"
                      >
                        SenseVoice
                      </el-dropdown-item>
                    </template>
                  </el-dropdown-menu>
                </template>
              </el-dropdown>
            </div>
          </div>
        </div>

        <!-- æœ€è¿‘æ–‡ä»¶ -->
        <div v-if="configStore.recentFiles.length > 0" class="recent-section">
          <p class="section-title">æœ€è¿‘æ‰“å¼€</p>
          <div class="recent-list">
            <div v-for="file in configStore.recentFiles.slice(0, 5)" :key="file.path" class="recent-item" @click="openRecentFile(file.path)">
              <i class="i-mdi-file-document-outline file-icon"></i>
              <span class="recent-name">{{ file.name }}</span>
              <span class="recent-time">{{ formatRelativeTime(file.lastOpened) }}</span>
              <button class="recent-delete-btn" @click="removeRecentFile(file.path, $event)" title="ä»åˆ—è¡¨ä¸­ç§»é™¤">
                <i class="i-mdi-close"></i>
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- æ‹–æ”¾æç¤ºé®ç½© -->
    <div v-if="isDragging" class="drag-overlay">
      <div class="drag-hint">
        <i class="i-mdi-file-upload-outline"></i>
        <p>é‡Šæ”¾ä»¥æ‰“å¼€æ–‡ä»¶</p>
      </div>
    </div>

    <!-- è½¬å½•è¿›åº¦å¯¹è¯æ¡† -->
    <el-dialog 
      v-model="showTranscriptionDialog" 
      :close-on-click-modal="false" 
      :close-on-press-escape="false" 
      :show-close="false"
      width="420px"
      class="transcription-dialog"
      :class="{ 'is-transcribing': isTranscribing }"
    >
      <div class="transcription-content" :class="{ 'is-transitioning': isTransitioningToEditor }">
        <!-- å…³é—­æŒ‰é’® -->
        <button v-if="!isTransitioningToEditor" class="close-btn" @click="cancelTranscription">
          <i class="i-mdi-close"></i>
        </button>
        
        <!-- è¿‡æ¸¡åˆ°ç¼–è¾‘å™¨çš„åŠ¨ç”» -->
        <template v-if="isTransitioningToEditor">
          <div class="transition-animation">
            <div class="success-icon">
              <i class="i-mdi-check-circle"></i>
            </div>
          </div>
          <p class="transition-status">æ­£åœ¨è¿›å…¥ç¼–è¾‘å™¨...</p>
        </template>
        
        <!-- è½¬å½•ä¸­çš„åŠ¨ç”» -->
        <template v-else>
          <!-- åŠ¨ç”»å›¾æ ‡åŒºåŸŸ -->
          <div class="transcription-animation">
            <div class="audio-wave">
              <span class="wave-bar"></span>
              <span class="wave-bar"></span>
              <span class="wave-bar"></span>
              <span class="wave-bar"></span>
              <span class="wave-bar"></span>
            </div>
            <div class="pulse-ring"></div>
            <div class="pulse-ring delay-1"></div>
            <div class="pulse-ring delay-2"></div>
          </div>
          
          <!-- è¿›åº¦ä¿¡æ¯ -->
          <div class="progress-info">
            <!-- ä¸‹è½½æˆ– SenseVoice è½¬å½•æ—¶æ˜¾ç¤ºçœŸå®è¿›åº¦æ¡ -->
            <template v-if="showRealProgress">
              <div class="progress-bar-container">
                <div class="progress-bar-track">
                  <div 
                    class="progress-bar-fill" 
                    :style="{ width: `${Math.round(transcriptionProgress)}%` }"
                  ></div>
                  <div 
                    class="progress-bar-glow" 
                    :style="{ left: `${Math.round(transcriptionProgress)}%` }"
                  ></div>
                </div>
              </div>
              <div class="progress-stats">
                <span class="progress-percentage">{{ Math.round(transcriptionProgress) }}%</span>
                <span class="progress-status">{{ localizedMessage }}</span>
              </div>
            </template>
            <!-- Whisper è½¬å½•æ—¶åªæ˜¾ç¤ºçŠ¶æ€æ–‡å­—ï¼ˆä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼‰ -->
            <template v-else>
              <p class="transcription-status">{{ localizedMessage }}</p>
            </template>
          </div>
          
          <!-- æç¤ºä¿¡æ¯ -->
          <p class="transcription-hint">
            <i class="i-mdi-information-outline"></i>
            <template v-if="transcriptionMessage.includes('ä¸‹è½½') || transcriptionMessage.includes('é¦–æ¬¡')">
              é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…
            </template>
            <template v-else>
              è½¬å½•æ—¶é—´å–å†³äºéŸ³é¢‘é•¿åº¦å’Œæ¨¡å‹å¤§å°
            </template>
          </p>
        </template>
      </div>
      
      <template #footer>
        <div v-if="!isTransitioningToEditor" class="dialog-footer">
          <el-button type="default" @click="cancelTranscription">
            å–æ¶ˆè½¬å½•
          </el-button>
        </div>
      </template>
    </el-dialog>
  </div>
</template>

<style scoped>
.welcome-page {
  width: 100%;
  height: 100vh;
  display: flex;
  flex-direction: column;
  background: #e8e8e8;
  overflow: hidden;
  position: relative;
}

.welcome-page.is-dragging {
  background: #ddd;
}

/* æ ‡é¢˜æ  */
.titlebar {
  height: 38px;
  background: transparent;
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  -webkit-app-region: drag;
  user-select: none;
}

.titlebar-title {
  font-size: 13px;
  font-weight: 500;
  color: #666;
}

/* ä¸»å†…å®¹åŒº */
.welcome-content {
  flex: 1;
  display: flex;
  justify-content: center;
  align-items: center;
  padding: 2rem;
}

.main-section {
  display: flex;
  flex-direction: column;
  gap: 1.5rem;
  width: 340px;
}

/* å“ç‰ŒåŒºåŸŸ */
.brand-area {
  display: flex;
  align-items: center;
  gap: 1rem;
  margin-bottom: 0.5rem;
}

.brand-icon {
  width: 48px;
  height: 48px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.brand-icon i {
  font-size: 42px;
  color: #333;
}

.brand-text {
  display: flex;
  flex-direction: column;
  gap: 2px;
}

.brand-title {
  font-size: 22px;
  font-weight: 700;
  color: #222;
  margin: 0;
  letter-spacing: -0.3px;
}

.brand-desc {
  font-size: 13px;
  color: #888;
  margin: 0;
}

/* åŒºå—æ ‡é¢˜ */
.section-title {
  font-size: 13px;
  font-weight: 500;
  color: #555;
  margin: 0 0 0.625rem;
}

/* æ“ä½œæŒ‰é’®ç»„ */
.action-buttons {
  display: flex;
  gap: 0.75rem;
}

/* ä¸»æŒ‰é’® */
.primary-btn {
  flex: 0 0 auto;
  padding: 0.625rem 1.25rem;
  background: #409eff;
  color: white;
  font-size: 13px;
  font-weight: 500;
  border: none;
  border-radius: 6px;
  cursor: pointer;
  transition: all 0.15s ease;
}

.primary-btn:hover:not(:disabled) {
  background: #337ecc;
}

.primary-btn:disabled {
  opacity: 0.7;
  cursor: not-allowed;
}

/* æ¬¡è¦æŒ‰é’® */
.secondary-btn {
  flex: 1;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.5rem;
  padding: 0.875rem 1rem;
  background: rgba(64, 158, 255, 0.08);
  color: #666;
  font-size: 14px;
  font-weight: 500;
  border: none;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.15s ease;
}

.secondary-btn:hover:not(:disabled) {
  background: rgba(64, 158, 255, 0.15);
  color: #409eff;
}

.secondary-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.secondary-btn i {
  font-size: 18px;
}

/* è½¬å½•æŒ‰é’®ç»„ */
.transcription-btn-group {
  flex: 1;
  display: flex;
}

.transcription-btn {
  flex: 1;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 0.375rem;
  padding: 0.625rem 0.75rem;
  background: rgba(64, 158, 255, 0.08);
  color: #666;
  font-size: 13px;
  font-weight: 500;
  border: none;
  border-radius: 6px 0 0 6px;
  cursor: pointer;
  transition: all 0.15s ease;
  white-space: nowrap;
}

.transcription-btn:hover:not(:disabled) {
  background: rgba(64, 158, 255, 0.15);
  color: #409eff;
}

.transcription-btn:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.transcription-btn i {
  font-size: 16px;
}

.model-badge {
  font-size: 10px;
  padding: 1px 5px;
  background: rgba(64, 158, 255, 0.15);
  color: #409eff;
  border-radius: 3px;
}

.transcription-dropdown {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 28px;
  background: rgba(64, 158, 255, 0.08);
  color: #666;
  border: none;
  border-left: 1px solid rgba(64, 158, 255, 0.15);
  border-radius: 0 6px 6px 0;
  cursor: pointer;
  transition: all 0.15s ease;
}

.transcription-dropdown:hover:not(:disabled) {
  background: rgba(64, 158, 255, 0.15);
  color: #409eff;
}

.transcription-dropdown:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

.transcription-dropdown i {
  font-size: 14px;
}

/* åªæœ‰ä¸€ä¸ªæ¨¡å‹æ—¶ï¼ŒæŒ‰é’®åœ†è§’å®Œæ•´ */
.transcription-btn-group .transcription-btn:only-child {
  border-radius: 6px;
}

/* ä¸‹æ‹‰èœå•åˆ†ç»„æ ‡é¢˜ */
:deep(.dropdown-header) {
  font-size: 11px !important;
  color: #909399 !important;
  font-weight: 600;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

:deep(.el-dropdown-menu__item.is-active) {
  color: #409eff;
  background: rgba(64, 158, 255, 0.08);
}

/* æœ€è¿‘æ–‡ä»¶ */
.recent-section {
  margin-top: 0.25rem;
}

.recent-list {
  display: flex;
  flex-direction: column;
  gap: 6px;
}

.recent-item {
  display: flex;
  align-items: center;
  gap: 0.625rem;
  padding: 0.625rem 0.75rem;
  background: rgba(255, 255, 255, 0.6);
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.15s ease;
}

.recent-item:hover {
  background: rgba(255, 255, 255, 0.9);
}

.recent-item .file-icon {
  font-size: 20px;
  color: #409eff;
  flex-shrink: 0;
}

.recent-name {
  flex: 1;
  font-size: 13px;
  color: #333;
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

.recent-time {
  font-size: 12px;
  color: #999;
  flex-shrink: 0;
}

.recent-delete-btn {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 24px;
  height: 24px;
  background: transparent;
  border: none;
  border-radius: 4px;
  cursor: pointer;
  color: #c0c4cc;
  transition: all 0.15s ease;
  flex-shrink: 0;
  margin-left: 4px;
}

.recent-delete-btn:hover {
  background: rgba(0, 0, 0, 0.06);
  color: #909399;
}

.recent-delete-btn i {
  font-size: 14px;
}



/* æ‹–æ”¾é®ç½© */
.drag-overlay {
  position: absolute;
  inset: 0;
  background: rgba(64, 158, 255, 0.06);
  backdrop-filter: blur(2px);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 100;
}

.drag-hint {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 0.75rem;
  padding: 2rem 3rem;
  background: white;
  border-radius: 16px;
  box-shadow: 0 8px 32px rgba(0, 0, 0, 0.12);
}

.drag-hint i {
  font-size: 48px;
  color: #409eff;
}

.drag-hint p {
  font-size: 15px;
  font-weight: 500;
  color: #333;
  margin: 0;
}

/* è½¬å½•å¯¹è¯æ¡† */
:deep(.transcription-dialog) {
  user-select: none;
  
  .el-dialog__header {
    display: none;
  }
  .el-dialog__body {
    padding: 0;
    user-select: none;
  }
  .el-dialog__footer {
    padding: 0 24px 20px;
    border-top: none;
    user-select: none;
  }
  .el-dialog {
    border-radius: 16px;
    overflow: hidden;
  }
  
  * {
    user-select: none;
  }
}

.transcription-content {
  position: relative;
  display: flex;
  flex-direction: column;
  align-items: center;
  padding: 32px 24px 24px;
  background: linear-gradient(180deg, #f0f7ff 0%, #fff 100%);
  user-select: none;
}

/* å…³é—­æŒ‰é’® */
.close-btn {
  position: absolute;
  top: 12px;
  right: 12px;
  width: 28px;
  height: 28px;
  display: flex;
  align-items: center;
  justify-content: center;
  background: transparent;
  border: none;
  border-radius: 6px;
  cursor: pointer;
  color: #909399;
  transition: all 0.15s ease;
}

.close-btn:hover {
  background: rgba(0, 0, 0, 0.06);
  color: #606266;
}

.close-btn i {
  font-size: 18px;
}

/* åŠ¨ç”»åŒºåŸŸ */
.transcription-animation {
  position: relative;
  width: 80px;
  height: 80px;
  display: flex;
  align-items: center;
  justify-content: center;
  margin-bottom: 20px;
}

/* éŸ³é¢‘æ³¢å½¢åŠ¨ç”» */
.audio-wave {
  display: flex;
  align-items: center;
  gap: 4px;
  z-index: 2;
}

.wave-bar {
  width: 4px;
  height: 20px;
  background: linear-gradient(180deg, #409eff 0%, #79bbff 100%);
  border-radius: 2px;
  animation: wave 1.2s ease-in-out infinite;
}

.wave-bar:nth-child(1) { animation-delay: 0s; height: 16px; }
.wave-bar:nth-child(2) { animation-delay: 0.1s; height: 24px; }
.wave-bar:nth-child(3) { animation-delay: 0.2s; height: 32px; }
.wave-bar:nth-child(4) { animation-delay: 0.3s; height: 24px; }
.wave-bar:nth-child(5) { animation-delay: 0.4s; height: 16px; }

@keyframes wave {
  0%, 100% { transform: scaleY(0.5); opacity: 0.6; }
  50% { transform: scaleY(1); opacity: 1; }
}

/* è„‰å†²ç¯åŠ¨ç”» */
.pulse-ring {
  position: absolute;
  width: 60px;
  height: 60px;
  border: 2px solid rgba(64, 158, 255, 0.3);
  border-radius: 50%;
  animation: pulse 2s ease-out infinite;
}

.pulse-ring.delay-1 { animation-delay: 0.6s; }
.pulse-ring.delay-2 { animation-delay: 1.2s; }

@keyframes pulse {
  0% {
    transform: scale(1);
    opacity: 0.6;
  }
  100% {
    transform: scale(2);
    opacity: 0;
  }
}



/* è¿›åº¦ä¿¡æ¯ */
.progress-info {
  width: 100%;
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.progress-bar-container {
  width: 100%;
  position: relative;
}

.progress-bar-track {
  width: 100%;
  height: 8px;
  background: #e4e7ed;
  border-radius: 4px;
  overflow: visible;
  position: relative;
}

.progress-bar-fill {
  height: 100%;
  background: linear-gradient(90deg, #409eff 0%, #79bbff 100%);
  border-radius: 4px;
  transition: width 0.3s ease;
  position: relative;
}



.progress-bar-glow {
  position: absolute;
  top: 50%;
  transform: translate(-50%, -50%);
  width: 12px;
  height: 12px;
  background: #409eff;
  border-radius: 50%;
  box-shadow: 0 0 12px rgba(64, 158, 255, 0.6);
  transition: left 0.3s ease;
}

.progress-stats {
  display: flex;
  justify-content: space-between;
  align-items: center;
  gap: 12px;
}

.progress-percentage {
  font-size: 24px;
  font-weight: 700;
  color: #409eff;
  font-variant-numeric: tabular-nums;
}

/* è½¬å½•çŠ¶æ€æ–‡å­— */
.transcription-status {
  font-size: 14px;
  color: #606266;
  text-align: center;
  margin: 0;
}

.progress-status {
  font-size: 13px;
  color: #909399;
  text-align: right;
  flex: 1;
  min-width: 0;
}

/* æç¤ºä¿¡æ¯ */
.transcription-hint {
  display: flex;
  align-items: center;
  gap: 6px;
  margin: 20px 0 0;
  padding: 10px 14px;
  background: rgba(64, 158, 255, 0.08);
  border-radius: 8px;
  font-size: 12px;
  color: #606266;
}

.transcription-hint i {
  font-size: 16px;
  color: #409eff;
  flex-shrink: 0;
}

/* å¯¹è¯æ¡†åº•éƒ¨ */
.dialog-footer {
  display: flex;
  justify-content: center;
}

.dialog-footer .el-button {
  min-width: 100px;
}

/* è¿‡æ¸¡åŠ¨ç”» */
.transcription-content.is-transitioning {
  padding: 48px 24px;
}

.transition-animation {
  position: relative;
  width: 56px;
  height: 56px;
  margin-bottom: 20px;
}

.success-icon {
  position: relative;
  width: 56px;
  height: 56px;
  display: flex;
  align-items: center;
  justify-content: center;
  background: linear-gradient(135deg, #409eff 0%, #79bbff 100%);
  border-radius: 50%;
  animation: popIn 0.5s cubic-bezier(0.34, 1.56, 0.64, 1);
}

.success-icon::before {
  content: '';
  position: absolute;
  inset: -4px;
  border-radius: 50%;
  background: linear-gradient(135deg, rgba(64, 158, 255, 0.3) 0%, rgba(121, 187, 255, 0.1) 100%);
  animation: ringPulse 0.8s ease-out;
}

.success-icon i {
  font-size: 28px;
  color: white;
}

@keyframes popIn {
  0% {
    transform: scale(0);
    opacity: 0;
  }
  50% {
    transform: scale(1.1);
  }
  100% {
    transform: scale(1);
    opacity: 1;
  }
}

@keyframes ringPulse {
  0% {
    transform: scale(0.8);
    opacity: 0;
  }
  50% {
    opacity: 1;
  }
  100% {
    transform: scale(1.3);
    opacity: 0;
  }
}

.transition-status {
  font-size: 14px;
  font-weight: 500;
  color: #606266;
  margin: 0;
  animation: fadeSlideIn 0.4s ease 0.15s both;
}

@keyframes fadeSlideIn {
  from {
    opacity: 0;
    transform: translateY(6px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}
</style>

<style>
/* å…¨å±€æ ·å¼ - ç¦æ­¢è½¬å½•å¯¹è¯æ¡†æ–‡å­—é€‰ä¸­ */
.transcription-dialog,
.transcription-dialog * {
  user-select: none !important;
  -webkit-user-select: none !important;
}
</style>
